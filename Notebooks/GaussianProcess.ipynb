{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "F62kjOCA2kJ4"
      ],
      "authorship_tag": "ABX9TyMYKuTJzyfXJulrsaHojBtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67c006756a31486d8f558fe5245eee94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d991e64cf32e4129a87c7b5a7444ddbe",
              "IPY_MODEL_62f6dbacccf04881a3f866d84ce459bd",
              "IPY_MODEL_f43cdacaa2334afcbd1e5e7ff5d055b5"
            ],
            "layout": "IPY_MODEL_9a139f1907cd4609a9198a6ce187c225"
          }
        },
        "d991e64cf32e4129a87c7b5a7444ddbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7da36b9829478dbc63731903d4db1e",
            "placeholder": "​",
            "style": "IPY_MODEL_3034c9fc22f643c59fd01f4f99fd22b6",
            "value": "100%"
          }
        },
        "62f6dbacccf04881a3f866d84ce459bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ed6114a3c6412085868adba997006e",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d12777d38bb6484b836332bed62c631e",
            "value": 100
          }
        },
        "f43cdacaa2334afcbd1e5e7ff5d055b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d0d07308c244709f49d92863b76245",
            "placeholder": "​",
            "style": "IPY_MODEL_2ce8d9c271c3449d9606ae2bbefb2734",
            "value": " 100/100 [00:13&lt;00:00,  7.66it/s, loss=0.532]"
          }
        },
        "9a139f1907cd4609a9198a6ce187c225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7da36b9829478dbc63731903d4db1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3034c9fc22f643c59fd01f4f99fd22b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97ed6114a3c6412085868adba997006e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12777d38bb6484b836332bed62c631e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8d0d07308c244709f49d92863b76245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce8d9c271c3449d9606ae2bbefb2734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cicl-iscl/LeWiDi_SemEval2023/blob/main/Notebooks/GaussianProcess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes\n",
        "\n",
        "ConvAbuse is just the dictionary as a string lol"
      ],
      "metadata": {
        "id": "_7BPCv2gZ5fR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfQMkjW8yVph"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install wandb\n",
        "!pip install torchsampler\n",
        "!pip install gpytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up wandb"
      ],
      "metadata": {
        "id": "FcZFOoO_NX8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "# config = dict (\n",
        "#   architecture = \"bert_arabic_english\",\n",
        "#   epochs = 1,\n",
        "#   batch_size = 4\n",
        "# )\n",
        "\n",
        "# run = wandb.init(\n",
        "#   project=\"capture-disagreement\",\n",
        "#   notes=\"test_run\",\n",
        "#   #name = \"test_run\",\n",
        "#   config=config,\n",
        "#   save_code = True,\n",
        "#   tags = [\"bert_arabic_english\", \"weighted_loss\", \"balanced_loss\", \"only_last_layer\"],\n",
        "#   #magic = True\n",
        "# )\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"capture-disagreement\",\n",
        "    save_code = True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "4mrjJxBANc2M",
        "outputId": "1019c5bf-9b71-457b-cfa4-21b026cff7f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meolian\u001b[0m (\u001b[33mcapture_disagreement\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230123_090540-nytze4nr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/capture_disagreement/capture-disagreement/runs/nytze4nr\" target=\"_blank\">likely-haze-47</a></strong> to <a href=\"https://wandb.ai/capture_disagreement/capture-disagreement\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/capture_disagreement/capture-disagreement\" target=\"_blank\">https://wandb.ai/capture_disagreement/capture-disagreement</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/capture_disagreement/capture-disagreement/runs/nytze4nr\" target=\"_blank\">https://wandb.ai/capture_disagreement/capture-disagreement/runs/nytze4nr</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "sZT9wpWdNeiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_multilingual_last_layer_dataset = run.use_artifact('capture_disagreement/capture-disagreement/bert_multilingual_last_layer_dataset:latest', type='dataset')\n",
        "bert_multilingual_last_layer_dataset_directory = bert_multilingual_last_layer_dataset.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmQZ6nip0NX1",
        "outputId": "3119de6d-547a-4ef2-d34e-11ec8ec93e93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bert_multilingual_last_layer_dataset:latest, 265.92MB. 10431 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   10431 of 10431 files downloaded.  \n",
            "Done. 0:0:1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "class ModelOutputDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, output_dir):\n",
        "        self.output_dir = output_dir\n",
        "        self.output_paths = [os.path.join(output_dir, path) for path in os.listdir(output_dir)]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.output_paths)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        output_path = self.output_paths[index]\n",
        "        data = torch.load(output_path, map_location=device)\n",
        "        return data"
      ],
      "metadata": {
        "id": "zxK4JWJm0URw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "S16g78UA2-gs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_multilingual_last_layer_dataset = ModelOutputDataset(bert_multilingual_last_layer_dataset_directory)"
      ],
      "metadata": {
        "id": "khQUcOYU0W_h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanced"
      ],
      "metadata": {
        "id": "xqN7cb495zCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import os\n",
        "# from collections import Counter\n",
        "\n",
        "# # Check if PyTorch version is greater than 1.5.0\n",
        "# if int(torch.__version__[0]) > 1 or (int(torch.__version__[0]) == 1 and int(torch.__version__[2]) >= 5):\n",
        "#     from torch.utils.data.sampler import WeightedRandomSampler\n",
        "# else:\n",
        "#     # Implement WeightedRandomSampler using custom code\n",
        "#     class WeightedRandomSampler:\n",
        "#         def __init__(self, weights, num_samples, replacement=True):\n",
        "#             self.weights = torch.DoubleTensor(weights)\n",
        "#             self.num_samples = num_samples\n",
        "#             self.replacement = replacement\n",
        "\n",
        "#         def __iter__(self):\n",
        "#             return iter(torch.multinomial(self.weights, self.num_samples, self.replacement))\n",
        "\n",
        "#         def __len__(self):\n",
        "#             return self.num_samples\n",
        "\n",
        "# class ModelOutputDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self, output_dir):\n",
        "#         self.output_dir = output_dir\n",
        "#         self.output_paths = [os.path.join(output_dir, path) for path in os.listdir(output_dir)]\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return len(self.output_paths)\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         output_path = self.output_paths[index]\n",
        "#         data = torch.load(output_path, map_location=device)\n",
        "#         return data\n",
        "\n",
        "# bert_multilingual_last_layer_dataset = ModelOutputDataset(bert_multilingual_last_layer_dataset_directory)\n",
        "\n",
        "# # Split the dataset into train and test\n",
        "# train_set, test_set = torch.utils.data.random_split(bert_multilingual_last_layer_dataset, [0.8, 0.2])\n",
        "# test_set, eval_set = torch.utils.data.random_split(test_set, [0.5, 0.5])\n",
        "\n",
        "# # Get the labels for each sample\n",
        "# train_labels = [data[\"labels\"].cpu().item() for data in train_set]\n",
        "# eval_labels = [data[\"labels\"] for data in eval_set]\n",
        "# test_labels = [data[\"labels\"] for data in test_set]\n",
        "\n",
        "# # Count the number of samples for each class in the train set\n",
        "# label_counts = Counter(train_labels)\n",
        "\n",
        "# # Calculate the weight for each sample\n",
        "# weights = [1.0 / label_counts[label] for label in train_labels]\n",
        "\n",
        "# # Create a weighted random sampler for the train set\n",
        "# sampler = WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "# # Set up a dataloader for the train set\n",
        "# train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=256, sampler=sampler)\n",
        "# eval_dataloader = torch.utils.data.DataLoader(eval_set, batch_size=256, shuffle=False)\n",
        "# test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "7LKQ6WYX52VL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unbalanced"
      ],
      "metadata": {
        "id": "yNy8nG9n79XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test\n",
        "train_set, test_set = torch.utils.data.random_split(bert_multilingual_last_layer_dataset, [0.8, 0.2])\n",
        "test_set, eval_set = torch.utils.data.random_split(test_set, [0.5, 0.5])\n",
        "\n",
        "\n",
        "# Set up a dataloader for the train set\n",
        "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False)\n",
        "eval_dataloader = torch.utils.data.DataLoader(eval_set, batch_size=1, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "FoVIIahw6DOU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0RRQrQT_S8ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "for i, batch in enumerate(train_dataloader):\n",
        "    inputs,  hard_labels = batch[\"output\"], batch[\"labels\"]\n",
        "    soft_labels = batch[\"soft_labels\"][\"0\"][0]#maybe other way around\n",
        "    train_x.append(inputs)\n",
        "    train_y.append(soft_labels)\n",
        "\n",
        "train_x = torch.cat(train_x, dim=0).to(device)\n",
        "train_y = torch.cat(train_y, dim=0).to(device)\n"
      ],
      "metadata": {
        "id": "ut7JaMnPuEuQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpytorch\n",
        "\n",
        "class GPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
        "                gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=768)),\n",
        "                num_dims=768, grid_size=100\n",
        "            )\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
        "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.scale_to_bounds(x)\n",
        "        mean = self.mean_module(x)\n",
        "        covar = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
        "\n",
        "# Define the likelihood function\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "\n",
        "# Create a model and move it to the GPU\n",
        "model = GPModel(train_x, train_y, likelihood)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDDvH0yC3ZPt",
        "outputId": "e690041e-5a26-4357-84bf-cb1403814fff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPModel(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (mean_module): ConstantMean()\n",
              "  (covar_module): ScaleKernel(\n",
              "    (base_kernel): RBFKernel(\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "    (raw_outputscale_constraint): Positive()\n",
              "  )\n",
              "  (scale_to_bounds): ScaleToBounds()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer and train the model\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.covar_module.parameters()},\n",
        "    {'params': model.mean_module.parameters()},\n",
        "    {'params': model.likelihood.parameters()},\n",
        "], lr=0.01)\n",
        "\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
      ],
      "metadata": {
        "id": "mK_E3EFw3dBW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "model.train()\n",
        "\n",
        "training_iterations = 100\n",
        "\n",
        "def train():\n",
        "    iterator = tqdm.notebook.tqdm(range(training_iterations))\n",
        "    for i in iterator:\n",
        "        # Zero backprop gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Get output from model\n",
        "        output = model(train_x)\n",
        "        # Calc loss and backprop derivatives\n",
        "        loss = -mll(output, train_y)\n",
        "        loss.backward()\n",
        "        iterator.set_postfix(loss=loss.item())\n",
        "        optimizer.step()\n",
        "\n",
        "%time train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "67c006756a31486d8f558fe5245eee94",
            "d991e64cf32e4129a87c7b5a7444ddbe",
            "62f6dbacccf04881a3f866d84ce459bd",
            "f43cdacaa2334afcbd1e5e7ff5d055b5",
            "9a139f1907cd4609a9198a6ce187c225",
            "9f7da36b9829478dbc63731903d4db1e",
            "3034c9fc22f643c59fd01f4f99fd22b6",
            "97ed6114a3c6412085868adba997006e",
            "d12777d38bb6484b836332bed62c631e",
            "e8d0d07308c244709f49d92863b76245",
            "2ce8d9c271c3449d9606ae2bbefb2734"
          ]
        },
        "id": "UZTsiLFRtEwI",
        "outputId": "c1b7d710-63ca-44eb-d339-0fe53a529aeb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67c006756a31486d8f558fe5245eee94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.7 s, sys: 92.4 ms, total: 12.8 s\n",
            "Wall time: 13.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = []\n",
        "test_y = []\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "    inputs,  hard_labels = batch[\"output\"], batch[\"labels\"]\n",
        "    soft_labels = batch[\"soft_labels\"][\"0\"][0]#maybe other way around\n",
        "    test_x.append(inputs)\n",
        "    test_y.append(soft_labels)\n",
        "\n",
        "test_x = torch.cat(test_x, dim=0).to(device)\n",
        "test_y = torch.cat(test_y, dim=0).to(device)"
      ],
      "metadata": {
        "id": "hmeYm8cj0Nqj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "likelihood.eval()\n",
        "with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\n",
        "    preds = model(test_x)"
      ],
      "metadata": {
        "id": "XGxIKHSQ0LDp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuknfQnn5vSb",
        "outputId": "1069dacc-69d8-4679-d2f9-e1a3e89fb8ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 0.3330,  ..., 0.8300, 1.0000, 0.6000], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.variance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIpmlUwY5VOu",
        "outputId": "9185e0a7-e6af-4e0c-bf25-39c54e92f298"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1337, 0.1396, 0.1698,  ..., 0.2153, 0.0246, 0.1687], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4a7ATcl5t4J",
        "outputId": "cc5c25c3-3268-405d-ff95-401ab7dc12a4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7499, 0.8908, 0.8772,  ..., 0.6311, 0.7996, 0.5067], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test MAE: {}'.format(torch.mean(torch.abs(preds.mean - test_y))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBshfNI0W-K",
        "outputId": "94124dae-7b64-47b7-ce0b-12964b34e154"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MAE: 0.23644913733005524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_clipped = torch.clip(preds.mean, 1e-12, 1. - 1e-12)\n",
        "preds_clipped = torch.clip(preds.mean, 1e-12, 1. - 1e-12)"
      ],
      "metadata": {
        "id": "jXeyJn0c2__1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
        "criterion(preds_clipped, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxupsq8t2ACZ",
        "outputId": "30eead5d-f7bf-4b6b-cc3a-c5b38c76d8ad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5436, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "rJFSTd2t4iku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ce 0.5398 , mae 0.23413577675819397, soft_labels = batch[\"soft_labels\"][\"0\"][0]\n",
        "1.8794 , .., soft_labels = batch[\"soft_labels\"][\"1\"][0]"
      ],
      "metadata": {
        "id": "U2CgRew94lpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternatives"
      ],
      "metadata": {
        "id": "R9UUC9Uf0go7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import GPy\n",
        "# import numpy as np\n",
        "\n",
        "# # Extract the inputs and outputs from the dataset\n",
        "# X = [batch[\"output\"] for batch in train_set]\n",
        "# Y = [batch[\"soft_labels\"] for batch in train_set]\n",
        "\n",
        "# # Convert the inputs and outputs to numpy arrays\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "\n",
        "# # Define the kernel for the GP\n",
        "# kernel = GPy.kern.RBF(input_dim=X.shape[1], ARD=True)\n",
        "\n",
        "# # Create the GP model\n",
        "# gp = GPy.models.GPRegression(X, Y, kernel)\n",
        "\n",
        "# # Optimize the model's hyperparameters\n",
        "# gp.optimize()\n"
      ],
      "metadata": {
        "id": "MAdLYg-EskSO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm_notebook\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import gpflow\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(embeddings, dataset['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# # train a Gaussian process model\n",
        "\n",
        "\n",
        "# kernel = gpflow.kernels.RBF()\n",
        "# gpmodel = gpflow.models.VGP(X_train, y_train, kern=kernel)\n",
        "\n",
        "# # optimize the model hyperparameters\n",
        "# opt = gpflow.optimizers.Scipy()\n",
        "# opt.minimize(gpmodel.training_loss, gpmodel.trainable_variables)\n",
        "\n",
        "# # use the trained model to predict the sexual abuse score for the test data with uncertainties\n",
        "# mean, var = gpmodel.predict_f(X_test)\n",
        "\n",
        "# # print the predictions and uncertainties\n",
        "# for i in range(len(mean)):\n",
        "#     print(f'Prediction: {mean[i]:.2f}, Uncertainty: {var[i]:.2f}')\n"
      ],
      "metadata": {
        "id": "wTtrwliPqu8D"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}