{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install wandb\n",
        "# !pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "4KRnpUy22K5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MTL DataAsTask approach\n",
        "- Pretrain Bert on all data and small output heads to make it learn a shared representation of disagreement\n",
        "- Create Heads for different tasks: mysogyny, sexism, aggressive language, ...\n",
        "  - USP: Run one input sentence for different heads, to understand the disagreement across topics\n",
        "  - Fine tune last layers build on a the fixed pre fine tuned Bert\n",
        "  - In our case: Different datasets for the tasks \n",
        "  - &rarr; 4 heads\n",
        "- Loss:\n",
        "  - BCE Loss for hard label and percentage of Soft Label\n",
        "  - Example: 2 of 6 annotator labeled 1:\n",
        "    - Hard label 0: Soft_label_1: 0.33 \n",
        "  - $Loss = (BCELoss(HardLabel) + BCELoss(SoftLabel1) * 2 )/2$\n",
        "- Output Layers\n",
        "  - Here: Just a few linear layers with tanh and dropout\n",
        "Modules\n",
        "- Only train output layers\n",
        "\n",
        "\n",
        "Further adjustements for DataAsTask Model:\n",
        "- Use more complex heads, f.e. Use of MultiHeadAttention\n",
        "- More datasets for the different headers\n",
        "- Different choice of heads\n",
        "  - Combination of KL divergence Loss and BCELoss, both o Soft Labels worked fine as well and focusses more on the disagreement than hard label\n",
        "- Better fine tuning with respect to LR, Optimizer, Loss (weights) to improve on unbalanced datasets \n",
        "\n"
      ],
      "metadata": {
        "id": "YmVysd855i69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**: \n"
      ],
      "metadata": {
        "id": "dBVN81rOm1PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8iiDkW4Dm0UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6275a0ce-17a5-4940-bcaf-df885b96c2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLUrOiEf2Sp6",
        "outputId": "7704ac50-618b-4b4f-ddd0-f6895943e51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msheuschk\u001b[0m (\u001b[33mcapture_disagreement\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from drive.MyDrive.cicl_data.helpers import read_data\n",
        "# from drive.MyDrive.cicl_data.code import CustomLabelDataset"
      ],
      "metadata": {
        "id": "ZedtcbT22LoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "# from datasets import Dataset\n",
        "import torch.nn.functional as Fun\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# from pytorch_lightning.trainer.supporters import CombinedLoader"
      ],
      "metadata": {
        "id": "RssAgMX314if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 14\n",
        "torch.manual_seed(seed)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "uLkclSt57CSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = read_data()\n",
        "# df_all = pd.concat([data_dict[k] for k in data_dict.keys()])"
      ],
      "metadata": {
        "id": "b0lq4E472D6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_soft_labels(row):\n",
        "  return row[1]"
      ],
      "metadata": {
        "id": "SWiX09DWgdTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in data_dict.keys():\n",
        "  data_dict[k][\"sl_1s\"] = data_dict[k][\"soft_list\"].apply(extract_soft_labels)"
      ],
      "metadata": {
        "id": "OC2b9Z_QgPGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxth0iIFMPDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"MTL_DaT\",\n",
        "    config={\n",
        "        \"epochs\": num_epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"device\": device,\n",
        "        \"Seed\": seed\n",
        "        },\n",
        "      save_code = True,\n",
        "      tags = [\"mulitBert\", \"MTL\", \"task_headers\", \"heads_with2_linLayer\", \"4_heads\", \"CE_Loss\", \"onlySoft\"]\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "L2JA9Tm0MPGw",
        "outputId": "d0ac95b2-f0e4-4795-f133-a133e19fc5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230129_170229-zmymq52y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/capture_disagreement/MTL_DaT/runs/zmymq52y\" target=\"_blank\">crimson-lantern-7</a></strong> to <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT\" target=\"_blank\">https://wandb.ai/capture_disagreement/MTL_DaT</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT/runs/zmymq52y\" target=\"_blank\">https://wandb.ai/capture_disagreement/MTL_DaT/runs/zmymq52y</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained model"
      ],
      "metadata": {
        "id": "-FFCNddg5uOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertModel, DistilBertTokenizer"
      ],
      "metadata": {
        "id": "rxMJS8EeKpgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maybe load from wandb in future\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased') # bert-base-multilingual-cased  / lanwuwei/GigaBERT-v4-Arabic-and-English"
      ],
      "metadata": {
        "id": "3K8_di7C2edU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MTLModel(nn.Module):\n",
        "  def __init__(self, base_model):\n",
        "    super().__init__()\n",
        "    self.bert = base_model\n",
        "    # self.linear = nn.Linear(768, 768)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.act = nn.Tanh()\n",
        "\n",
        "    self.linear_hsH = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    self.linear_hsS = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "\n",
        "    self.linear_mdH = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    self.linear_mdS = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    \n",
        "    self.linear_abuH = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    self.linear_abuS = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    \n",
        "    self.linear_misH = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    self.linear_misS = nn.Sequential(nn.Linear(768, 768), nn.Tanh(), nn.Dropout(0.2), nn.Linear(768, 384), nn.Tanh(), nn.Linear(384, 1))\n",
        "    \n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, task):\n",
        "    \"\"\"a linear layer on top of the pooled output (https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bertforsequenceclassification)\"\"\"\n",
        "    \"\"\"tasks: HS, MD, Abu, Mis\"\"\"\n",
        "\n",
        "    x = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    # x = self.linear(x.pooler_output)\n",
        "    # x = x.pooler_output\n",
        "    hidden_state = x[0]\n",
        "    x = hidden_state[:, 0]\n",
        "\n",
        "    # TODO: Exchange to attention modules\n",
        "    if task.upper() == \"HS\":\n",
        "      x_h = self.linear_hsH(x)\n",
        "      x_s = self.linear_hsS(x)\n",
        "    elif task.upper() == \"MD\":\n",
        "      x_h = self.linear_mdH(x)\n",
        "      x_s = self.linear_mdS(x)\n",
        "    elif task.upper() == \"ABU\":\n",
        "      x_h = self.linear_abuH(x)\n",
        "      x_s = self.linear_abuS(x)\n",
        "    elif task.upper() == \"MIS\":\n",
        "      x_h = self.linear_misH(x)\n",
        "      x_s = self.linear_misS(x)\n",
        "\n",
        "    x_h =  torch.flatten(self.sigmoid(x_h))\n",
        "    x_s =  torch.flatten(self.sigmoid(x_s))\n",
        "\n",
        "    # x = Fun.log_softmax(x, dim=1)  # And use Kl and NLL Loss\n",
        "    # x = self.softmax(x)  # CE\n",
        "\n",
        "    return x_h.to(dtype=torch.float64), x_s.to(dtype=torch.float64)"
      ],
      "metadata": {
        "id": "NfZHklM7Z5Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "model = MTLModel(base_model)"
      ],
      "metadata": {
        "id": "Rq7U6dMZBJlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a54ec96-31e3-4bf5-b9e6-6f803359ca8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "xWUpdKOTQXwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained_weights = torch.load('/content/drive/MyDrive/cicl_data/model_params/rom5000_1H2N_BCE_05HL.pt') # , map_location=torch.device('cpu'))\n",
        "art_name = 'model_param:v10'\n",
        "weight_dir = f'/content/drive/MyDrive/cicl_data/model_params/{art_name}'\n",
        "\n",
        "if not os.path.exists(weight_dir):\n",
        "  artifact = run.use_artifact(f\"MTL_DBert/{art_name}\")  # 2H1N_LRcos_SoftLoss*2  CE=0.408\n",
        "  weight_dir = artifact.download(weight_dir)"
      ],
      "metadata": {
        "id": "_d2kZdHdLDEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# , map_location=torch.device('cpu'))\n",
        "model.load_state_dict(torch.load(f\"{weight_dir}/model.pt\"), strict=False)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "dfyBVb-qD9YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vUW65MBWQ706"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize headers with pretrained linear layer (if needed)\n",
        "# import copy\n",
        "\"\"\"\n",
        "with torch.no_grad():\n",
        "  for name, param in model.named_parameters():\n",
        "    if \"linear_\" in name:\n",
        "      if \".weight\" in name:\n",
        "        param = torch.nn.Parameter(copy.deepcopy(pretrained_weights['linear.weight']))\n",
        "      elif \".bias\" in name:\n",
        "        param = copy.deepcopy(pretrained_weights['linear.bias'])\n",
        "      param.requires_grad = False\n",
        "      print(name)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UWVgqeJhD75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "87e69353-385f-4411-e1c8-71d6b2656079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith torch.no_grad():\\n  for name, param in model.named_parameters():\\n    if \"linear_\" in name:\\n      if \".weight\" in name:\\n        param = torch.nn.Parameter(copy.deepcopy(pretrained_weights[\\'linear.weight\\']))\\n      elif \".bias\" in name:\\n        param = copy.deepcopy(pretrained_weights[\\'linear.bias\\'])\\n      param.requires_grad = False\\n      print(name)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUyQw6Z-Ypk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "OFp2k-qB51d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLabelDataset(Dataset):\n",
        "    def __init__(self, df_all):\n",
        "        self.text = list(map(self.tokenize_func, df_all[\"text\"]))\n",
        "        self.soft_labels = df_all[\"soft_list\"] \n",
        "        self.hard_labels = df_all[\"hard_label\"]\n",
        "        self.hard_labels_1h = Fun.one_hot(torch.tensor(df_all['hard_label'].values))\n",
        "        self.soft_labels_1s = df_all[\"sl_1s\"] # 0.33 of soft labels like {\"1\": 0.33, \"0\": 0.67}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "      \n",
        "    def tokenize_func(self, text):\n",
        "        return tokenizer(text, padding=\"max_length\", truncation=True, max_length=240, add_special_tokens=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input = {\"attention_mask\": torch.tensor(self.text[idx][\"attention_mask\"]),\n",
        "                 \"input_ids\": torch.tensor(self.text[idx][\"input_ids\"])}\n",
        "        return input, self.hard_labels_1h[idx], torch.tensor(self.soft_labels[idx]), torch.tensor(self.hard_labels[idx]), torch.tensor(self.soft_labels_1s[idx])\n"
      ],
      "metadata": {
        "id": "rmYCQ5IzGQSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init dataset\n",
        "task_keys = [\"HS\", \"MD\", \"Abu\", \"Mis\"]\n",
        "batch_size = 64\n",
        "train_dataloaders = {}\n",
        "train_size = 0\n",
        "for key in data_dict.keys():\n",
        "  dataset = CustomLabelDataset(data_dict[key])\n",
        "  train_size += len(dataset)\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True)\n",
        "  \n",
        "  if \"HS-\" in key:\n",
        "    train_dataloaders[\"HS\"] = dataloader\n",
        "  elif \"MD-\" in key:\n",
        "    train_dataloaders[\"MD\"] = dataloader\n",
        "  elif \"Conv\" in key:\n",
        "    train_dataloaders[\"Abu\"] = dataloader\n",
        "  elif \"MIS\" in key:\n",
        "    train_dataloaders[\"Mis\"] = dataloader\n",
        "\n",
        "# train_dataloader = CombinedLoader(dataloaders, mode=\"max_size_cycle\")\n",
        "# train_size = len(train_dataloader)"
      ],
      "metadata": {
        "id": "Asl4kclO2egC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzQSCFDmhFyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Evaluation dataset\n",
        "data_dict_dev = read_data(\"dev\")\n",
        "# df_dev = pd.concat([data_dict_dev[k] for k in data_dict_dev.keys()])\n",
        "\n",
        "# df_dev[\"sl_1s\"] = df_dev[\"soft_list\"].apply(extract_soft_labels)\n",
        "for k in data_dict_dev.keys():\n",
        "  data_dict_dev[k][\"sl_1s\"] = data_dict_dev[k][\"soft_list\"].apply(extract_soft_labels)\n",
        "\n",
        "dev_batch_size = 64\n",
        "dev_dataloaders = {}\n",
        "\n",
        "for key in data_dict_dev.keys():\n",
        "  dev_dataset = CustomLabelDataset(data_dict_dev[key])\n",
        "\n",
        "  dev_dataloader = DataLoader(\n",
        "      dev_dataset,\n",
        "      batch_size=dev_batch_size)\n",
        "  if \"HS-\" in key:\n",
        "    dev_dataloaders[\"HS\"] = dev_dataloader\n",
        "  elif \"MD-\" in key:\n",
        "    dev_dataloaders[\"MD\"] = dev_dataloader\n",
        "  elif \"Conv\" in key:\n",
        "    dev_dataloaders[\"Abu\"] = dev_dataloader\n",
        "  elif \"MIS\" in key:\n",
        "    dev_dataloaders[\"Mis\"] = dev_dataloader\n",
        "  \n",
        "# Use dict instead of CombinedLoader for evaluation\n",
        "# dev_dataloader = CombinedLoader(dev_dataloaders, mode=\"max_size_cycle\")\n"
      ],
      "metadata": {
        "id": "7rQ8gtQcbBXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict_dev.keys(), dev_dataloaders.keys()"
      ],
      "metadata": {
        "id": "myt86lNzsh0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45853c82-798b-4248-fd0d-82c3e7dc1e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['ArMIS', 'MD-Agreement', 'ConvAbuse', 'HS-Brexit']),\n",
              " dict_keys(['Mis', 'MD', 'Abu', 'HS']))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization"
      ],
      "metadata": {
        "id": "NwEKXBtI59g7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0XVIRyn2ei-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "# nll_loss = nn.CrossEntropyLoss()\n",
        "# kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "44oJzJhg2elN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before Training"
      ],
      "metadata": {
        "id": "ZHvCCIut6Ms8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6OcK6ZkRAbC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1de1c2eb-5e4b-4cae-a77c-319ab71fa180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230126_193501-r9vcocn3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/capture_disagreement/MTL_DaT/runs/r9vcocn3\" target=\"_blank\">beaming-fuse-4</a></strong> to <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT\" target=\"_blank\">https://wandb.ai/capture_disagreement/MTL_DaT</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/capture_disagreement/MTL_DaT/runs/r9vcocn3\" target=\"_blank\">https://wandb.ai/capture_disagreement/MTL_DaT/runs/r9vcocn3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7anpJ2mwtral"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tasks = ['Mis', 'MD', 'Abu', 'HS']"
      ],
      "metadata": {
        "id": "r9XwgNpfElGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JtzfYOaElKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from drive.MyDrive.cicl_data.helpers import ce_eval_func\n",
        "def ce_eval_func_task(model, eval_dataloader, task, epsilon=1e-12, device=\"cuda\"):\n",
        "  model.eval()\n",
        "  cross_error = 0\n",
        "  for i, batch in enumerate(eval_dataloader):\n",
        "    input_ids = batch[0][\"input_ids\"].to(device, dtype=torch.long)\n",
        "    attention_mask = batch[0][\"attention_mask\"].to(device, dtype=torch.long)\n",
        "    soft_labels = batch[2].to(device, dtype=torch.float64)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      _, pred = model(input_ids, attention_mask=attention_mask, task=task)\n",
        "\n",
        "    pred = pred.reshape(len(pred), 1)\n",
        "    probabilities = torch.cat((1-pred, pred), dim=-1)\n",
        "    # probabilities = torch.softmax(pred, axis=-1)\n",
        "    \n",
        "    predictions = torch.clip(probabilities, epsilon, 1. - epsilon)\n",
        "    cross_error += -torch.sum(soft_labels * torch.log(predictions + 1e-9))\n",
        "  ce_score = cross_error / len(eval_dataloader.dataset)\n",
        "  # print(k, ce_score)\n",
        "  return ce_score.item()\n",
        "\n",
        "\n",
        "# from drive.MyDrive.cicl_data.helpers import ce_eval_func\n",
        "def ce_eval_func(model, eval_dataloader, epsilon=1e-12, device=\"cuda\"):\n",
        "  model.eval()\n",
        "  all_ce_scores = []\n",
        "\n",
        "  for task in eval_dataloader.keys():\n",
        "    cross_error = 0\n",
        "    for i, batch in enumerate(eval_dataloader[task]):\n",
        "      input_ids = batch[0][\"input_ids\"].to(device, dtype=torch.long)\n",
        "      attention_mask = batch[0][\"attention_mask\"].to(device, dtype=torch.long)\n",
        "      soft_labels = batch[2].to(device, dtype=torch.float64)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        _, pred = model(input_ids, attention_mask=attention_mask, task=task) #\n",
        "      pred = pred.reshape(len(pred), 1)\n",
        "      probabilities = torch.cat((1-pred, pred), dim=-1)\n",
        "      # probabilities = torch.softmax(pred, axis=-1)\n",
        "      \n",
        "      predictions = torch.clip(probabilities, epsilon, 1. - epsilon)\n",
        "      cross_error += -torch.sum(soft_labels * torch.log(predictions + 1e-9))\n",
        "    ce_score = cross_error / len(eval_dataloader[task].dataset)\n",
        "    # print(k, ce_score)\n",
        "    all_ce_scores.append(ce_score.item())\n",
        "  return all_ce_scores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4U6NEklMdfxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ce_before = []\n",
        "for current_task in all_tasks:\n",
        "  ce_before = ce_eval_func_task(model, dev_dataloaders[current_task], current_task, device=device)\n",
        "  print(f\"{current_task} - CE before training: {ce_before}\")\n",
        "  wandb.log({f\"eval/ce_before_{current_task}\": ce_before})\n",
        "  all_ce_before.append(ce_before)\n",
        "\n",
        "wandb.log({\"eval/ce_before_training\": np.array(all_ce_before).mean()})\n",
        "print(f\"Mean CE before training: {np.array(all_ce_before).mean()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9IipQBcwOlQ",
        "outputId": "38091564-83bf-46e3-a295-6fb45cb84412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mis - CE before training: 0.6914898645714476\n",
            "MD - CE before training: 0.6797025561632969\n",
            "Abu - CE before training: 0.6466916819287633\n",
            "HS - CE before training: 0.7137583381067459\n",
            "Mean CE before training: 0.6829106101925635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeKCeRbFGLh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRWvZ87QPOuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "k8V0dFP-GRvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup"
      ],
      "metadata": {
        "id": "_KPmNwOaKXsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "num_epochs = 100\n",
        "LR = 1e-5\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# num_training_steps = num_epochs * len(train_dataloader)\n",
        "#lr_scheduler = get_scheduler( name=\"constant\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "O9HdhoELGLr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_grad_of_head(model, task):\n",
        "  for name, param in model.named_parameters():\n",
        "    if f\"_{task.lower()}\" in name:\n",
        "      param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "HJyk8dvEG6jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration, task in enumerate(all_tasks):\n",
        "  # Train\n",
        "  print(f\"Start training: {task}\")\n",
        "  last_ce = 10\n",
        "  smallest_ce = 10\n",
        "  eval_counter = False\n",
        "  task_dataloader = train_dataloaders[task]\n",
        "  \n",
        "  # Load best model of last task\n",
        "  if iteration != 0:\n",
        "    model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "  # Set params.requires_grad = False for unused heads?\n",
        "  enable_grad_of_head(model, task)\n",
        "  optimizer = AdamW(model.parameters(), lr=LR)\n",
        "  train_steps = int(num_epochs * len(task_dataloader) * 0.95)\n",
        "  warmup_steps = num_epochs * len(task_dataloader) - train_steps\n",
        "  lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=train_steps, num_cycles=num_epochs/10)\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    model.train()\n",
        "    loss_batches = 0\n",
        "    epoch_loss = 0\n",
        "    epoch_len = len(task_dataloader)\n",
        "    \n",
        "    log_n_batches = int(epoch_len/2)\n",
        "\n",
        "    for i, batch in enumerate(task_dataloader):\n",
        "      optimizer.zero_grad()\n",
        "      loss = 0\n",
        "      \n",
        "      input_ids = batch[0][\"input_ids\"].to(device, dtype=torch.long)\n",
        "      attention_mask = batch[0][\"attention_mask\"].to(device, dtype=torch.long)\n",
        "      # hard_label_1h = batch[1].to(device)\n",
        "      # soft_labels = batch[2].to(device, dtype=torch.float64)\n",
        "      hard_label = batch[3].to(device, dtype=torch.float64)\n",
        "      soft_labels_1 = batch[4].to(device, dtype=torch.float64)\n",
        "\n",
        "      # predict\n",
        "      pred_hl, pred_sl = model(input_ids=input_ids, attention_mask=attention_mask, task=task)\n",
        "\n",
        "      # Loss\n",
        "      loss = loss_fn(pred_sl, soft_labels_1)*2\n",
        "      loss += loss_fn(pred_hl, hard_label) \n",
        "      loss = loss/2\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      lr_scheduler.step()\n",
        "\n",
        "      # Log\n",
        "      loss_batches += loss.item()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "      if i % log_n_batches == 0:\n",
        "        if i != 0:\n",
        "          # print(f\"{e+1} - {task}: Last {log_n_batches} batches avg loss: {loss_batches/log_n_batches:>7f}  [{i}/{epoch_len}]\")\n",
        "          wandb.log({f\"train/loss_over_batches_{task}\": loss_batches/log_n_batches})\n",
        "        loss_batches = 0\n",
        "    \n",
        "    epoch_loss /= i  \n",
        "    print(f\"{task} - Epoch [{e+1}/{num_epochs}] mean loss: {epoch_loss:>6f}\")\n",
        "    wandb.log({f\"train/epoch_loss_{task}\": epoch_loss})\n",
        "\n",
        "    # Eval error\n",
        "    ce = ce_eval_func_task(model, dev_dataloaders[task], task, device=device)\n",
        "    print(f\"{task} - Epoch [{e+1}/{num_epochs}] Mean CE  : {ce:>6f}\")\n",
        "    wandb.log({f\"eval/epoch_ce_{task}\": {task: ce}})\n",
        "\n",
        "    # Stop after Eval CE raises 2 times in a row (Simple early stopping)\n",
        "    if ce > last_ce:\n",
        "      if eval_counter is True:\n",
        "        print(\"Interrupt: Eval Error is raising\")\n",
        "        break;\n",
        "      eval_counter = True\n",
        "    elif ce < smallest_ce:\n",
        "      torch.save(model.state_dict(), f'model.pt')\n",
        "      print(f\"{task} - Epoch [{e+1}/{num_epochs}] Save model state\")\n",
        "      eval_counter = False\n",
        "      smallest_ce = ce\n",
        "    \n",
        "    last_ce = ce\n",
        "  print(f\"{task}: Smallest CE: {smallest_ce}\")\n",
        "  print(\"-----------------------------------------\")\n",
        "  print(\"\\n \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_BqUVXBK6Btg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2136ff17-d6d6-4d35-9325-829d1a6501dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training: Mis\n",
            "Mis - Epoch [1/100] mean loss: 0.791987\n",
            "Mis - Epoch [1/100] Mean CE  : 0.615513\n",
            "Mis - Epoch [1/100] Save model state\n",
            "Mis - Epoch [2/100] mean loss: 0.776747\n",
            "Mis - Epoch [2/100] Mean CE  : 0.616267\n",
            "Mis - Epoch [3/100] mean loss: 0.778867\n",
            "Mis - Epoch [3/100] Mean CE  : 0.617622\n",
            "Interrupt: Eval Error is raising\n",
            "Mis: Smallest CE: 0.615513131456999\n",
            "-----------------------------------------\n",
            "\n",
            " \n",
            "\n",
            "Start training: MD\n",
            "MD - Epoch [1/100] mean loss: 0.845701\n",
            "MD - Epoch [1/100] Mean CE  : 0.583503\n",
            "MD - Epoch [1/100] Save model state\n",
            "MD - Epoch [2/100] mean loss: 0.752860\n",
            "MD - Epoch [2/100] Mean CE  : 0.544265\n",
            "MD - Epoch [2/100] Save model state\n",
            "MD - Epoch [3/100] mean loss: 0.652463\n",
            "MD - Epoch [3/100] Mean CE  : 0.528059\n",
            "MD - Epoch [3/100] Save model state\n",
            "MD - Epoch [4/100] mean loss: 0.599361\n",
            "MD - Epoch [4/100] Mean CE  : 0.531350\n",
            "MD - Epoch [5/100] mean loss: 0.581121\n",
            "MD - Epoch [5/100] Mean CE  : 0.532356\n",
            "Interrupt: Eval Error is raising\n",
            "MD: Smallest CE: 0.5280594349869607\n",
            "-----------------------------------------\n",
            "\n",
            " \n",
            "\n",
            "Start training: Abu\n",
            "Abu - Epoch [1/100] mean loss: 0.992374\n",
            "Abu - Epoch [1/100] Mean CE  : 0.601465\n",
            "Abu - Epoch [1/100] Save model state\n",
            "Abu - Epoch [2/100] mean loss: 0.862501\n",
            "Abu - Epoch [2/100] Mean CE  : 0.489652\n",
            "Abu - Epoch [2/100] Save model state\n",
            "Abu - Epoch [3/100] mean loss: 0.666666\n",
            "Abu - Epoch [3/100] Mean CE  : 0.371634\n",
            "Abu - Epoch [3/100] Save model state\n",
            "Abu - Epoch [4/100] mean loss: 0.490084\n",
            "Abu - Epoch [4/100] Mean CE  : 0.289726\n",
            "Abu - Epoch [4/100] Save model state\n",
            "Abu - Epoch [5/100] mean loss: 0.373218\n",
            "Abu - Epoch [5/100] Mean CE  : 0.248779\n",
            "Abu - Epoch [5/100] Save model state\n",
            "Abu - Epoch [6/100] mean loss: 0.311402\n",
            "Abu - Epoch [6/100] Mean CE  : 0.234161\n",
            "Abu - Epoch [6/100] Save model state\n",
            "Abu - Epoch [7/100] mean loss: 0.282644\n",
            "Abu - Epoch [7/100] Mean CE  : 0.230595\n",
            "Abu - Epoch [7/100] Save model state\n",
            "Abu - Epoch [8/100] mean loss: 0.263164\n",
            "Abu - Epoch [8/100] Mean CE  : 0.230196\n",
            "Abu - Epoch [8/100] Save model state\n",
            "Abu - Epoch [9/100] mean loss: 0.261750\n",
            "Abu - Epoch [9/100] Mean CE  : 0.230706\n",
            "Abu - Epoch [10/100] mean loss: 0.255783\n",
            "Abu - Epoch [10/100] Mean CE  : 0.231072\n",
            "Interrupt: Eval Error is raising\n",
            "Abu: Smallest CE: 0.23019614656565626\n",
            "-----------------------------------------\n",
            "\n",
            " \n",
            "\n",
            "Start training: HS\n",
            "HS - Epoch [1/100] mean loss: 1.154349\n",
            "HS - Epoch [1/100] Mean CE  : 0.699553\n",
            "HS - Epoch [1/100] Save model state\n",
            "HS - Epoch [2/100] mean loss: 1.106354\n",
            "HS - Epoch [2/100] Mean CE  : 0.657078\n",
            "HS - Epoch [2/100] Save model state\n",
            "HS - Epoch [3/100] mean loss: 1.011263\n",
            "HS - Epoch [3/100] Mean CE  : 0.594088\n",
            "HS - Epoch [3/100] Save model state\n",
            "HS - Epoch [4/100] mean loss: 0.890561\n",
            "HS - Epoch [4/100] Mean CE  : 0.523030\n",
            "HS - Epoch [4/100] Save model state\n",
            "HS - Epoch [5/100] mean loss: 0.769826\n",
            "HS - Epoch [5/100] Mean CE  : 0.454585\n",
            "HS - Epoch [5/100] Save model state\n",
            "HS - Epoch [6/100] mean loss: 0.644196\n",
            "HS - Epoch [6/100] Mean CE  : 0.404436\n",
            "HS - Epoch [6/100] Save model state\n",
            "HS - Epoch [7/100] mean loss: 0.575603\n",
            "HS - Epoch [7/100] Mean CE  : 0.373552\n",
            "HS - Epoch [7/100] Save model state\n",
            "HS - Epoch [8/100] mean loss: 0.512462\n",
            "HS - Epoch [8/100] Mean CE  : 0.356205\n",
            "HS - Epoch [8/100] Save model state\n",
            "HS - Epoch [9/100] mean loss: 0.500683\n",
            "HS - Epoch [9/100] Mean CE  : 0.346403\n",
            "HS - Epoch [9/100] Save model state\n",
            "HS - Epoch [10/100] mean loss: 0.473369\n",
            "HS - Epoch [10/100] Mean CE  : 0.341053\n",
            "HS - Epoch [10/100] Save model state\n",
            "HS - Epoch [11/100] mean loss: 0.457925\n",
            "HS - Epoch [11/100] Mean CE  : 0.338162\n",
            "HS - Epoch [11/100] Save model state\n",
            "HS - Epoch [12/100] mean loss: 0.464397\n",
            "HS - Epoch [12/100] Mean CE  : 0.336730\n",
            "HS - Epoch [12/100] Save model state\n",
            "HS - Epoch [13/100] mean loss: 0.444569\n",
            "HS - Epoch [13/100] Mean CE  : 0.336211\n",
            "HS - Epoch [13/100] Save model state\n",
            "HS - Epoch [14/100] mean loss: 0.448202\n",
            "HS - Epoch [14/100] Mean CE  : 0.336133\n",
            "HS - Epoch [14/100] Save model state\n",
            "HS - Epoch [15/100] mean loss: 0.434035\n",
            "HS - Epoch [15/100] Mean CE  : 0.330034\n",
            "HS - Epoch [15/100] Save model state\n",
            "HS - Epoch [16/100] mean loss: 0.414575\n",
            "HS - Epoch [16/100] Mean CE  : 0.326479\n",
            "HS - Epoch [16/100] Save model state\n",
            "HS - Epoch [17/100] mean loss: 0.409857\n",
            "HS - Epoch [17/100] Mean CE  : 0.324546\n",
            "HS - Epoch [17/100] Save model state\n",
            "HS - Epoch [18/100] mean loss: 0.405129\n",
            "HS - Epoch [18/100] Mean CE  : 0.323563\n",
            "HS - Epoch [18/100] Save model state\n",
            "HS - Epoch [19/100] mean loss: 0.403876\n",
            "HS - Epoch [19/100] Mean CE  : 0.323084\n",
            "HS - Epoch [19/100] Save model state\n",
            "HS - Epoch [20/100] mean loss: 0.393525\n",
            "HS - Epoch [20/100] Mean CE  : 0.322852\n",
            "HS - Epoch [20/100] Save model state\n",
            "HS - Epoch [21/100] mean loss: 0.390803\n",
            "HS - Epoch [21/100] Mean CE  : 0.322740\n",
            "HS - Epoch [21/100] Save model state\n",
            "HS - Epoch [22/100] mean loss: 0.398950\n",
            "HS - Epoch [22/100] Mean CE  : 0.322701\n",
            "HS - Epoch [22/100] Save model state\n",
            "HS - Epoch [23/100] mean loss: 0.386903\n",
            "HS - Epoch [23/100] Mean CE  : 0.322695\n",
            "HS - Epoch [23/100] Save model state\n",
            "HS - Epoch [24/100] mean loss: 0.386937\n",
            "HS - Epoch [24/100] Mean CE  : 0.322346\n",
            "HS - Epoch [24/100] Save model state\n",
            "HS - Epoch [25/100] mean loss: 0.374992\n",
            "HS - Epoch [25/100] Mean CE  : 0.322330\n",
            "HS - Epoch [25/100] Save model state\n",
            "HS - Epoch [26/100] mean loss: 0.379429\n",
            "HS - Epoch [26/100] Mean CE  : 0.322489\n",
            "HS - Epoch [27/100] mean loss: 0.368924\n",
            "HS - Epoch [27/100] Mean CE  : 0.322733\n",
            "Interrupt: Eval Error is raising\n",
            "HS: Smallest CE: 0.3223301833316413\n",
            "-----------------------------------------\n",
            "\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXt89Yi36B1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTJsKeQIYdSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model dependent improvements:\n"
      ],
      "metadata": {
        "id": "lZ5Ws3sQXfaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "QB3Oa4j36PJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_best = MTLModel(base_model)\n",
        "model_best.load_state_dict(torch.load('model.pt'))\n",
        "model_best = model_best.to(device)"
      ],
      "metadata": {
        "id": "iwGwtu0B6BbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Cross Entropy Error\n",
        "cross_error = ce_eval_func(model_best, dev_dataloaders, device=device)\n",
        "print(f\"CE error: {np.array(cross_error).mean()}\")\n",
        "wandb.log({\"dev/ce\": np.array(cross_error).mean()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcCmaLsH6iOW",
        "outputId": "bdd74614-60f8-4837-c61c-0a1e406c876e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE error: 0.42402365965746025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "cross_error = 0\n",
        "epsilon = 1e-12\n",
        "for i, batch in enumerate(dev_dataloaders[\"HS\"]):\n",
        "  input_ids = batch[0][\"input_ids\"].to(device, dtype = torch.long)\n",
        "  attention_mask = batch[0][\"attention_mask\"].to(device, dtype = torch.long)\n",
        "  soft_labels = batch[2].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, pred = model_best(input_ids, attention_mask=attention_mask, task=\"HS\")\n",
        "  pred = pred.reshape(len(pred), 1)\n",
        "  probabilities = torch.cat((1-pred, pred), dim=-1)\n",
        "  \n",
        "  predictions = torch.clip(probabilities, epsilon, 1. - epsilon)\n",
        "  cross_error += -torch.sum(soft_labels * torch.log(predictions + 1e-9))\n",
        "  break\n",
        "\n"
      ],
      "metadata": {
        "id": "suoX3FT2jBBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(soft_labels)"
      ],
      "metadata": {
        "id": "M92VuoY1jBEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed602f02-2013-405b-9110-7960ea2ebe27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9606, 0.0394],\n",
            "        [0.9262, 0.0738],\n",
            "        [0.7549, 0.2451],\n",
            "        [0.9601, 0.0399],\n",
            "        [0.9644, 0.0356],\n",
            "        [0.9528, 0.0472],\n",
            "        [0.9640, 0.0360],\n",
            "        [0.8209, 0.1791],\n",
            "        [0.7713, 0.2287],\n",
            "        [0.8993, 0.1007],\n",
            "        [0.8088, 0.1912],\n",
            "        [0.8553, 0.1447],\n",
            "        [0.9236, 0.0764],\n",
            "        [0.5227, 0.4773],\n",
            "        [0.8554, 0.1446],\n",
            "        [0.9593, 0.0407],\n",
            "        [0.7671, 0.2329],\n",
            "        [0.7185, 0.2815],\n",
            "        [0.9144, 0.0856],\n",
            "        [0.9609, 0.0391],\n",
            "        [0.9374, 0.0626],\n",
            "        [0.8648, 0.1352],\n",
            "        [0.9681, 0.0319],\n",
            "        [0.8568, 0.1432],\n",
            "        [0.9384, 0.0616],\n",
            "        [0.8917, 0.1083],\n",
            "        [0.7087, 0.2913],\n",
            "        [0.8558, 0.1442],\n",
            "        [0.6817, 0.3183],\n",
            "        [0.9553, 0.0447],\n",
            "        [0.9663, 0.0337],\n",
            "        [0.9444, 0.0556],\n",
            "        [0.7789, 0.2211],\n",
            "        [0.8864, 0.1136],\n",
            "        [0.9617, 0.0383],\n",
            "        [0.9393, 0.0607],\n",
            "        [0.2098, 0.7902],\n",
            "        [0.9725, 0.0275],\n",
            "        [0.9574, 0.0426],\n",
            "        [0.6362, 0.3638],\n",
            "        [0.9376, 0.0624],\n",
            "        [0.9705, 0.0295],\n",
            "        [0.9734, 0.0266],\n",
            "        [0.9640, 0.0360],\n",
            "        [0.9597, 0.0403],\n",
            "        [0.8058, 0.1942],\n",
            "        [0.9621, 0.0379],\n",
            "        [0.9388, 0.0612],\n",
            "        [0.4650, 0.5350],\n",
            "        [0.9640, 0.0360],\n",
            "        [0.9671, 0.0329],\n",
            "        [0.9331, 0.0669],\n",
            "        [0.5729, 0.4271],\n",
            "        [0.9620, 0.0380],\n",
            "        [0.9667, 0.0333],\n",
            "        [0.9557, 0.0443],\n",
            "        [0.9720, 0.0280],\n",
            "        [0.8494, 0.1506],\n",
            "        [0.8383, 0.1617],\n",
            "        [0.9510, 0.0490],\n",
            "        [0.9692, 0.0308],\n",
            "        [0.6680, 0.3320],\n",
            "        [0.9130, 0.0870],\n",
            "        [0.9610, 0.0390]], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[1.0000, 0.0000],\n",
            "        [0.6700, 0.3300],\n",
            "        [0.5000, 0.5000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [0.3300, 0.6700],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.6700, 0.3300],\n",
            "        [0.6700, 0.3300],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.6700, 0.3300],\n",
            "        [0.6700, 0.3300],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [0.5000, 0.5000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.1700, 0.8300],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.8300, 0.1700],\n",
            "        [0.8300, 0.1700],\n",
            "        [0.0000, 1.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.5000, 0.5000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000],\n",
            "        [0.3300, 0.6700],\n",
            "        [1.0000, 0.0000],\n",
            "        [1.0000, 0.0000]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_hl = pred.reshape(len(pred_hl), 1)\n",
        "pred_hl = torch.cat((1-pred_hl, pred_hl), dim=-1)\n",
        "print(pred_hl)"
      ],
      "metadata": {
        "id": "dPMlfy-U7OBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finish"
      ],
      "metadata": {
        "id": "eydOBaKsiz5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), 'model.pt')\n",
        "# model.load_state_dict(torch.load(PATH), strict=False)\n",
        "artifact = wandb.Artifact(name='model_param', type='model')\n",
        "artifact.add_file(local_path=\"model.pt\")\n",
        "run.log_artifact(artifact);"
      ],
      "metadata": {
        "id": "Yek9Cza6lOUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "U36WeQhk43v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vOTDCRf43yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bYN4cn0tgwCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNTuvRmYgwJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSV files - Practice phase"
      ],
      "metadata": {
        "id": "fqrKNQOPgnmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "hv13ro9PgmWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"/content/ArMIS_results.tsv\", \"/content/ConvAbuse_results.tsv\", \"/content/HS-Brexit_results.tsv\", \"/content/MD-Agreement_results.tsv\"]\n",
        "epsilon = 1e-12\n",
        "\n",
        "for fp in filepaths:\n",
        "  if os.path.exists(fp):\n",
        "    os.remove(fp)\n",
        "\n",
        "for key in data_dict_dev.keys():\n",
        "  data_dict_dev[key][\"sl_1s\"] = data_dict_dev[key][\"soft_list\"].apply(extract_soft_labels)\n",
        "  tsv_dataset = CustomLabelDataset(data_dict_dev[key])\n",
        "  tsv_dataloader = DataLoader(tsv_dataset, shuffle=False, batch_size=1)\n",
        "  filepath_write = f\"/content/{key}_results.tsv\"\n",
        "  if \"HS-\" in key:\n",
        "    task = \"HS\"\n",
        "  elif \"MD-\" in key:\n",
        "    task = \"MD\"\n",
        "  elif \"Conv\" in key:\n",
        "    task = \"Abu\"\n",
        "  elif \"MIS\" in key:\n",
        "    task = \"Mis\"\n",
        "    \n",
        "  with open(filepath_write, 'w', newline='') as tsvfile:\n",
        "      writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
        "      for i, batch in enumerate(tqdm(tsv_dataloader, 0)):\n",
        "        input_ids = batch[0][\"input_ids\"].to(device, dtype = torch.long)\n",
        "        attention_mask = batch[0][\"attention_mask\"].to(device, dtype = torch.long)\n",
        "        token_type_ids = batch[0][\"token_type_ids\"].to(device, dtype = torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          pred = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, task=task)\n",
        "        # logits = pred.logits\n",
        "        # probability = torch.softmax(pred, axis=-1)\n",
        "        pred = pred.reshape(len(pred), 1)\n",
        "        probability = torch.cat((1-pred, pred), dim=-1)\n",
        "        # probability = torch.softmax(pred, axis=-1)\n",
        "        prediction = torch.round(pred)\n",
        "        probability = torch.clip(probability, epsilon, 1. - epsilon) # Really necessary?\n",
        "        writer.writerow([int(prediction[0].item()), probability[0][0].item(), probability[0][1].item()])\n"
      ],
      "metadata": {
        "id": "6YA4In8ggmZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "filepath = \"res.zip\" \n",
        "\n",
        "if os.path.exists(filepath):\n",
        "    os.remove(filepath)\n",
        "\n",
        "#loop over filepath names throws an string index out of range for whatever reason(also can't use content here, not sure why)\n",
        "with ZipFile(filepath, 'w') as zipObj:\n",
        "  zipObj.write(\"MD-Agreement_results.tsv\")\n",
        "  zipObj.write(\"ArMIS_results.tsv\")\n",
        "  zipObj.write(\"HS-Brexit_results.tsv\")\n",
        "  zipObj.write(\"ConvAbuse_results.tsv\")"
      ],
      "metadata": {
        "id": "Y5E4llTxgmcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"res.zip\")"
      ],
      "metadata": {
        "id": "YvIfIi4Tgmga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vj_Tv-EyRXPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVeOwggWhkxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TSV Files - Evaluation Phase"
      ],
      "metadata": {
        "id": "xR7ZSP4GRgLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data_test(usage=\"train\"):\n",
        "  \"\"\"@usage: 'train'/'dev'\"\"\"\n",
        "  data = dict()\n",
        "  datasets = ['ArMIS','MD-Agreement','ConvAbuse', 'HS-Brexit'] \n",
        "\n",
        "  for current_dataset in datasets:\n",
        "    data[current_dataset] = {}\n",
        "    current_file = '/content/drive/MyDrive/cicl_data/' + current_dataset + '_dataset/' + current_dataset + '_'+ usage +'.json' \n",
        "    data[current_dataset] = json.load(open(current_file, 'r', encoding = 'UTF-8'))                                   \n",
        " \n",
        "  def extract_soft_labels(row):\n",
        "    return list(row.values())\n",
        "\n",
        "  def transform_data(data, name):\n",
        "    data = data[name]\n",
        "    df = pd.DataFrame(data).transpose()\n",
        "    df = df.astype({\"hard_label\": int}, errors='ignore') \n",
        "    df['data_set'] = name\n",
        "    df[\"soft_list\"] = df[\"soft_label\"].apply(extract_soft_labels)\n",
        "    return df\n",
        "\n",
        "  dfs = [transform_data(data, k) for k in data.keys()]\n",
        "\n",
        "  data_dict = {'ArMIS': dfs[0],'MD-Agreement': dfs[1],'ConvAbuse': dfs[2], 'HS-Brexit': dfs[3]}\n",
        "  # df = pd.concat(dfs)\n",
        "  return data_dict"
      ],
      "metadata": {
        "id": "815W7FDIRXnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestLabelDataset(Dataset):\n",
        "    def __init__(self, df_all):\n",
        "        self.text = list(map(self.tokenize_func, df_all[\"text\"]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "      \n",
        "    def tokenize_func(self, text):\n",
        "        return tokenizer(text, truncation=True, max_length=MaxLen, padding=\"max_length\", add_special_tokens=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input = {\"attention_mask\": torch.tensor(self.text[idx][\"attention_mask\"]),\n",
        "                 \"input_ids\": torch.tensor(self.text[idx][\"input_ids\"])}\n",
        "        return input\n"
      ],
      "metadata": {
        "id": "A5BOCFXFRXrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict_test = read_data_test(\"test\")"
      ],
      "metadata": {
        "id": "6-N2o2ZjhSB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MaxLen = 240"
      ],
      "metadata": {
        "id": "pdYr8ChLhSFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"/content/ArMIS_results.tsv\", \"/content/ConvAbuse_results.tsv\", \"/content/HS-Brexit_results.tsv\", \"/content/MD-Agreement_results.tsv\"]\n",
        "epsilon = 1e-12\n",
        "\n",
        "for fp in filepaths:\n",
        "  if os.path.exists(fp):\n",
        "    os.remove(fp)"
      ],
      "metadata": {
        "id": "Mj3Aec6AhSJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = [\"/content/ArMIS_results.tsv\", \"/content/ConvAbuse_results.tsv\", \"/content/HS-Brexit_results.tsv\", \"/content/MD-Agreement_results.tsv\"]\n",
        "epsilon = 1e-12\n",
        "\n",
        "for fp in filepaths:\n",
        "  if os.path.exists(fp):\n",
        "    os.remove(fp)\n",
        "\n",
        "for key in data_dict_test.keys():\n",
        "  # data_dict_test[key][\"sl_1s\"] = data_dict_test[key][\"soft_list\"].apply(extract_soft_labels)\n",
        "  tsv_dataset = TestLabelDataset(data_dict_test[key])\n",
        "  tsv_dataloader = DataLoader(tsv_dataset, shuffle=False, batch_size=1)\n",
        "  filepath_write = f\"/content/{key}_results.tsv\"\n",
        "  \n",
        "  if \"HS-\" in key:\n",
        "    task = \"HS\"\n",
        "  elif \"MD-\" in key:\n",
        "    task = \"MD\"\n",
        "  elif \"Conv\" in key:\n",
        "    task = \"Abu\"\n",
        "  elif \"MIS\" in key:\n",
        "    task = \"Mis\"\n",
        "\n",
        "  with open(filepath_write, 'w', newline='') as tsvfile:\n",
        "      writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
        "      for i, batch in enumerate(tqdm(tsv_dataloader, 0)):\n",
        "        input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          predH, predS = best_model(input_ids, attention_mask=attention_mask, task=task)\n",
        "        pred = predS.reshape(len(predS), 1)\n",
        "        probability = torch.cat((1-predS, predS), dim=-1)\n",
        "        # probability = torch.softmax(pred2, axis=-1)\n",
        "        prediction = torch.round(predH)\n",
        "        probability = torch.clip(probability, epsilon, 1. - epsilon)\n",
        "        writer.writerow([int(prediction[0].item()), probability[0].item(), probability[1].item()])\n"
      ],
      "metadata": {
        "id": "mTnec_XyhSM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "filepath = \"res_test.zip\" \n",
        "\n",
        "if os.path.exists(filepath):\n",
        "    os.remove(filepath)\n",
        "\n",
        "#loop over filepath names throws an string index out of range for whatever reason(also can't use content here, not sure why)\n",
        "with ZipFile(filepath, 'w') as zipObj:\n",
        "  zipObj.write(\"MD-Agreement_results.tsv\")\n",
        "  zipObj.write(\"ArMIS_results.tsv\")\n",
        "  zipObj.write(\"HS-Brexit_results.tsv\")\n",
        "  zipObj.write(\"ConvAbuse_results.tsv\")"
      ],
      "metadata": {
        "id": "xpCSQIi5hSQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "vfNKgfdihbgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}