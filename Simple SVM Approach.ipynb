{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e02fb5c",
   "metadata": {},
   "source": [
    "# SVM Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a7fa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e10e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "datasets = ['ArMIS','MD-Agreement','ConvAbuse', 'HS-Brexit'] \n",
    "splits = ['train','dev']\n",
    "for current_dataset in datasets:\n",
    "    data[current_dataset] = {}\n",
    "    for current_split in splits:\n",
    "        current_file = './data/data_practice/' + current_dataset + '_dataset/' + current_dataset + '_' + current_split + '.json' \n",
    "        data[current_dataset][current_split] = json.load(open(current_file, 'r', encoding = 'UTF-8'))                                   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b871c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96a423a0",
   "metadata": {},
   "source": [
    "### Simple SVM classifier\n",
    "For a simple start just using word count and inverse document frequency to create simple vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "816d20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC, SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b177b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myf1_score(conf_m):\n",
    "    precision = conf_m[0][0] /  (conf_m[0][0] + conf_m[1][0])\n",
    "    recall =  conf_m[0][0] / (conf_m[0][0] + conf_m[0][1])\n",
    "\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d291cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleSVM(df, stop_words_lang=\"english\"):\n",
    "    # 1. Split into X and y\n",
    "    X = df['text']\n",
    "    y = df['hard_label']\n",
    "\n",
    "    # 2. Use CountVectorizer and remove stop words\n",
    "    vectorizer = CountVectorizer(stop_words=stop_words_lang)\n",
    "    X_vec = vectorizer.fit_transform(X).todense()\n",
    "\n",
    "    # 3. tdf idf transformation\n",
    "    tfidf = TfidfTransformer()\n",
    "    X_tfidf = tfidf.fit_transform(np.asarray(X_vec)).todense()\n",
    "\n",
    "    # 4. train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.3, random_state = 0)\n",
    "    \n",
    "    # 5. Fit SVM\n",
    "    classifier = SVC(kernel='linear')\n",
    "    classifier.fit(np.asarray(X_train), y_train)\n",
    "    y_pred = classifier.predict(np.asarray(X_test))\n",
    "    \n",
    "    # Evaluation\n",
    "    conf_m = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Accuracy: {(conf_m[0][0] + conf_m[1][1]) / conf_m.sum()}\")\n",
    "    print(f\"F1_score: {myf1_score(conf_m)}\")\n",
    "    \n",
    "    return conf_m, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9c1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    data = data[\"train\"]\n",
    "    df = pd.DataFrame(data).transpose()\n",
    "    df = df.astype({\"hard_label\": int}, errors='raise') \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7d8e6",
   "metadata": {},
   "source": [
    "#### Brexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfc7492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation task</th>\n",
       "      <th>number of annotations</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotators</th>\n",
       "      <th>lang</th>\n",
       "      <th>hard_label</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>split</th>\n",
       "      <th>other_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; I'm so glad about #Brexit.. My a...</td>\n",
       "      <td>hate speech detection</td>\n",
       "      <td>6</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>Ann1,Ann2,Ann3,Ann4,Ann5,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'other annotations': {'aggressive language de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT &lt;user&gt;: There was more to #Brexit than immi...</td>\n",
       "      <td>hate speech detection</td>\n",
       "      <td>6</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>Ann1,Ann2,Ann3,Ann4,Ann5,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'other annotations': {'aggressive language de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At the end of the day, the leave campaign won ...</td>\n",
       "      <td>hate speech detection</td>\n",
       "      <td>6</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>Ann1,Ann2,Ann3,Ann4,Ann5,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'other annotations': {'aggressive language de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So the reducing migration thing wasn't quite w...</td>\n",
       "      <td>hate speech detection</td>\n",
       "      <td>6</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>Ann1,Ann2,Ann3,Ann4,Ann5,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'other annotations': {'aggressive language de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Brit Immigrant Asks Britain to Become India’...</td>\n",
       "      <td>hate speech detection</td>\n",
       "      <td>6</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>Ann1,Ann2,Ann3,Ann4,Ann5,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'other annotations': {'aggressive language de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        annotation task  \\\n",
       "1  <user> <user> I'm so glad about #Brexit.. My a...  hate speech detection   \n",
       "2  RT <user>: There was more to #Brexit than immi...  hate speech detection   \n",
       "3  At the end of the day, the leave campaign won ...  hate speech detection   \n",
       "4  So the reducing migration thing wasn't quite w...  hate speech detection   \n",
       "5  A Brit Immigrant Asks Britain to Become India’...  hate speech detection   \n",
       "\n",
       "  number of annotations  annotations                     annotators lang  \\\n",
       "1                     6  0,0,0,0,0,0  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6   en   \n",
       "2                     6  0,0,0,0,0,0  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6   en   \n",
       "3                     6  0,0,0,0,0,0  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6   en   \n",
       "4                     6  0,0,0,0,0,0  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6   en   \n",
       "5                     6  0,0,0,0,0,0  Ann1,Ann2,Ann3,Ann4,Ann5,Ann6   en   \n",
       "\n",
       "   hard_label            soft_label  split  \\\n",
       "1           0  {'0': 1.0, '1': 0.0}  train   \n",
       "2           0  {'0': 1.0, '1': 0.0}  train   \n",
       "3           0  {'0': 1.0, '1': 0.0}  train   \n",
       "4           0  {'0': 1.0, '1': 0.0}  train   \n",
       "5           0  {'0': 1.0, '1': 0.0}  train   \n",
       "\n",
       "                                          other_info  \n",
       "1  {'other annotations': {'aggressive language de...  \n",
       "2  {'other annotations': {'aggressive language de...  \n",
       "3  {'other annotations': {'aggressive language de...  \n",
       "4  {'other annotations': {'aggressive language de...  \n",
       "5  {'other annotations': {'aggressive language de...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brexit = transform_data(data['HS-Brexit'])\n",
    "df_brexit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f10671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9110169491525424\n",
      "F1_score: 0.953229398663697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[214,   0],\n",
       "       [ 21,   1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_m , y_pred = simpleSVM(df_brexit)\n",
    "conv_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c5d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e051a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d239d804",
   "metadata": {},
   "source": [
    "#### ConvAbuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b2251d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation task</th>\n",
       "      <th>number of annotations</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotators</th>\n",
       "      <th>lang</th>\n",
       "      <th>hard_label</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>split</th>\n",
       "      <th>other_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"prev_agent\": \"Please go on.\", \"prev_user\": \"...</td>\n",
       "      <td>abusivness detection</td>\n",
       "      <td>3</td>\n",
       "      <td>1,1,1</td>\n",
       "      <td>Ann2,Ann3,Ann7</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"prev_agent\": \"How long have you been on the ...</td>\n",
       "      <td>abusivness detection</td>\n",
       "      <td>3</td>\n",
       "      <td>1,1,1</td>\n",
       "      <td>Ann3,Ann7,Ann8</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"prev_agent\": \"You are being a bit negative.\"...</td>\n",
       "      <td>abusivness detection</td>\n",
       "      <td>2</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>Ann1,Ann7</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0.5, '1': 0.5}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"prev_agent\": \"Will you be travelling in Econ...</td>\n",
       "      <td>abusivness detection</td>\n",
       "      <td>2</td>\n",
       "      <td>1,1</td>\n",
       "      <td>Ann3,Ann6</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'bot': 'CarbonBot', 'other_annotations': {'ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{\"prev_agent\": \"Will you be travelling in Econ...</td>\n",
       "      <td>abusivness detection</td>\n",
       "      <td>3</td>\n",
       "      <td>1,1,1</td>\n",
       "      <td>Ann1,Ann2,Ann3</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'bot': 'CarbonBot', 'other_annotations': {'ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       annotation task  \\\n",
       "1  {\"prev_agent\": \"Please go on.\", \"prev_user\": \"...  abusivness detection   \n",
       "2  {\"prev_agent\": \"How long have you been on the ...  abusivness detection   \n",
       "3  {\"prev_agent\": \"You are being a bit negative.\"...  abusivness detection   \n",
       "4  {\"prev_agent\": \"Will you be travelling in Econ...  abusivness detection   \n",
       "5  {\"prev_agent\": \"Will you be travelling in Econ...  abusivness detection   \n",
       "\n",
       "  number of annotations annotations      annotators lang  hard_label  \\\n",
       "1                     3       1,1,1  Ann2,Ann3,Ann7   en           0   \n",
       "2                     3       1,1,1  Ann3,Ann7,Ann8   en           0   \n",
       "3                     2        -1,1       Ann1,Ann7   en           0   \n",
       "4                     2         1,1       Ann3,Ann6   en           0   \n",
       "5                     3       1,1,1  Ann1,Ann2,Ann3   en           0   \n",
       "\n",
       "             soft_label  split  \\\n",
       "1  {'0': 1.0, '1': 0.0}  train   \n",
       "2  {'0': 1.0, '1': 0.0}  train   \n",
       "3  {'0': 0.5, '1': 0.5}  train   \n",
       "4  {'0': 1.0, '1': 0.0}  train   \n",
       "5  {'0': 1.0, '1': 0.0}  train   \n",
       "\n",
       "                                          other_info  \n",
       "1  {'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...  \n",
       "2  {'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...  \n",
       "3  {'bot': 'E.L.I.Z.A.', 'other_annotations': {'a...  \n",
       "4  {'bot': 'CarbonBot', 'other_annotations': {'ab...  \n",
       "5  {'bot': 'CarbonBot', 'other_annotations': {'ab...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conv = transform_data(data[\"ConvAbuse\"])\n",
    "df_conv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48523b0e",
   "metadata": {},
   "source": [
    "Different text format to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b72e7c36",
   "metadata": {},
   "source": [
    "#### MD-Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdfe72c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation task</th>\n",
       "      <th>number of annotations</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotators</th>\n",
       "      <th>lang</th>\n",
       "      <th>hard_label</th>\n",
       "      <th>soft_label</th>\n",
       "      <th>split</th>\n",
       "      <th>other_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; No way Jose!!</td>\n",
       "      <td>offensiveness detection</td>\n",
       "      <td>5</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "      <td>Ann418,Ann266,Ann149,Ann730,Ann345</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'domain': 'Elections2020'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good god, what is the matter with people ?</td>\n",
       "      <td>offensiveness detection</td>\n",
       "      <td>5</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "      <td>Ann733,Ann422,Ann779,Ann514,Ann777</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'domain': 'Covid-19'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; &lt;user&gt; Um the Kurds are h...</td>\n",
       "      <td>offensiveness detection</td>\n",
       "      <td>5</td>\n",
       "      <td>0,0,0,0,1</td>\n",
       "      <td>Ann425,Ann511,Ann779,Ann420,Ann721</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0.8, '1': 0.2}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'domain': 'Elections2020'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is WRONG with these people?</td>\n",
       "      <td>offensiveness detection</td>\n",
       "      <td>5</td>\n",
       "      <td>0,0,0,0,0</td>\n",
       "      <td>Ann632,Ann179,Ann701,Ann201,Ann661</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 1.0, '1': 0.0}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'domain': 'BLM'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;user&gt; This earpiece too plus a wire on his sl...</td>\n",
       "      <td>offensiveness detection</td>\n",
       "      <td>5</td>\n",
       "      <td>1,0,0,0,0</td>\n",
       "      <td>Ann266,Ann168,Ann149,Ann381,Ann774</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>{'0': 0.8, '1': 0.2}</td>\n",
       "      <td>train</td>\n",
       "      <td>{'domain': 'Elections2020'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          annotation task  \\\n",
       "1                        <user> <user> No way Jose!!  offensiveness detection   \n",
       "2         Good god, what is the matter with people ?  offensiveness detection   \n",
       "3  <user> <user> <user> <user> Um the Kurds are h...  offensiveness detection   \n",
       "4                   What is WRONG with these people?  offensiveness detection   \n",
       "5  <user> This earpiece too plus a wire on his sl...  offensiveness detection   \n",
       "\n",
       "  number of annotations annotations                          annotators lang  \\\n",
       "1                     5   0,0,0,0,0  Ann418,Ann266,Ann149,Ann730,Ann345   en   \n",
       "2                     5   0,0,0,0,0  Ann733,Ann422,Ann779,Ann514,Ann777   en   \n",
       "3                     5   0,0,0,0,1  Ann425,Ann511,Ann779,Ann420,Ann721   en   \n",
       "4                     5   0,0,0,0,0  Ann632,Ann179,Ann701,Ann201,Ann661   en   \n",
       "5                     5   1,0,0,0,0  Ann266,Ann168,Ann149,Ann381,Ann774   en   \n",
       "\n",
       "   hard_label            soft_label  split                   other_info  \n",
       "1           0  {'0': 1.0, '1': 0.0}  train  {'domain': 'Elections2020'}  \n",
       "2           0  {'0': 1.0, '1': 0.0}  train       {'domain': 'Covid-19'}  \n",
       "3           0  {'0': 0.8, '1': 0.2}  train  {'domain': 'Elections2020'}  \n",
       "4           0  {'0': 1.0, '1': 0.0}  train            {'domain': 'BLM'}  \n",
       "5           0  {'0': 0.8, '1': 0.2}  train  {'domain': 'Elections2020'}  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_md = transform_data(data[\"MD-Agreement\"])\n",
    "df_md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19afefb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7750252780586451\n",
      "F1_score: 0.45532435740514077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1347,   66],\n",
       "       [ 379,  186]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv_m , y_pred = simpleSVM(df_md)\n",
    "conv_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db5ef4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a while"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5f16a",
   "metadata": {},
   "source": [
    "#### ArMIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = transform_data(data[\"ArMIS\"])\n",
    "df_ar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpleSVM(df_ar, stop_words_lang=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862da85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f88bbb2",
   "metadata": {},
   "source": [
    "## Brexit SVM per Group\n",
    "\n",
    "Train a Regression Model per Annotator Group to have models fitted to the perceptions which then can be compared.\n",
    "\n",
    "Ann1,2,3 are target (muslim) group Ann4,5,6 are control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90117caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'other annotations': {'aggressive language detection': '0,0,0,0,0,0',\n",
       "  'offensive language detection': '1,1,1,0,0,1'},\n",
       " 'annotators group': 'group1,group1,group1,group2,group2,group2',\n",
       " 'group1': 'target group',\n",
       " 'group2': 'control group'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brexit[\"other_info\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ab722da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ann1,Ann2,Ann3,Ann4,Ann5,Ann6    784\n",
       "Name: annotators, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brexit[\"annotators\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9101408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split labels into control and target groups\n",
    "y_t = []\n",
    "y_c = []\n",
    "for i in df_brexit[\"annotations\"]:\n",
    "    labels = list(map(int, i.split(\",\")))\n",
    "    y_t.append(np.mean(labels[:3]))\n",
    "    y_c.append(np.mean(labels[3:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a88803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_brexit['text']\n",
    "\n",
    "# 2. Use CountVectorizer and remove stop words\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X_vec = vectorizer.fit_transform(X).todense()\n",
    "\n",
    "# 3. tdf idf transformation\n",
    "tfidf = TfidfTransformer()\n",
    "X_tfidf = tfidf.fit_transform(np.asarray(X_vec)).todense()\n",
    "\n",
    "# 4. train test split\n",
    "X_train, X_test, y_t_train, y_t_test = train_test_split(X_tfidf, y_t, test_size = 0.3, random_state = 0)\n",
    "_, _, y_c_train, y_c_test = train_test_split(X_tfidf, y_c, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa986c3d",
   "metadata": {},
   "source": [
    "Use Regression to get a soft evaluation on how high the consent per group is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b838998",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_c = SVR(kernel='linear')\n",
    "reg_c.fit(np.asarray(X_train), y_c_train)\n",
    "y_c_pred = reg_c.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e4fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_t = SVR(kernel='linear')\n",
    "reg_t.fit(np.asarray(X_train), y_t_train)\n",
    "y_t_pred = reg_t.predict(np.asarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6136bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## given code snippet\n",
    "def cross_entropy(targets_soft, predictions_soft, epsilon = 1e-12):                                \n",
    "    predictions = np.clip(predictions_soft, epsilon, 1. - epsilon)                                      \n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets_soft*np.log(predictions+1e-9))/N\n",
    "    return ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02a46245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = (np.array(y_c_test) + np.array(y_t_test)) / 2\n",
    "y_pred = (y_c_pred + y_t_pred) / 2\n",
    "\n",
    "target_soft = []\n",
    "for i in y_target:\n",
    "    target_soft.append([i, 1-i])\n",
    "    \n",
    "y_soft_pred = []\n",
    "for i in y_pred:\n",
    "    y_soft_pred.append([i, 1-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e0041ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3294894054239409"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = cross_entropy(target_soft, y_soft_pred)\n",
    "ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fa679",
   "metadata": {},
   "source": [
    "This cross entropy error seems ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7a1854e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32702354685923984"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control previous result by doing regression within one model\n",
    "y = []\n",
    "for i in df_brexit[\"soft_label\"]:\n",
    "    y.append(int(i[\"1\"]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size = 0.3, random_state = 0)\n",
    "reg = SVR(kernel='linear')\n",
    "reg.fit(np.asarray(X_train), y_train)\n",
    "y_pred_whole = reg_c.predict(np.asarray(X_test))\n",
    "y_soft_pred_whole = []\n",
    "for i in y_pred_whole:\n",
    "    y_soft_pred_whole.append([i, 1-i])\n",
    "target_soft_whole = []\n",
    "for i in y_test:\n",
    "    target_soft_whole.append([i, 1-i])\n",
    "\n",
    "ce = cross_entropy(target_soft_whole, y_soft_pred_whole)\n",
    "ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997e85c",
   "metadata": {},
   "source": [
    "The Cross entropy does not change much, just a little bit better. So the combination of both models work as well as using just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c454f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40d72587",
   "metadata": {},
   "source": [
    "My idea was that we now have two regression parameter sets as well as estimates per group.\n",
    "Therefore we could check, f.e:\n",
    "- where do the weights of the linear regression differ the most between the two groups. So, check which words imply a different perception regarding the offensivness\n",
    "- For which texts do the predicted labels differ the most. Is it possible to extract topics where \"most\" disagreement occurs\n",
    "\n",
    "But I do not feel like this is really useful, now that I've done it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b340ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac35db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a14e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3ff3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
